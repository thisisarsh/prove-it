{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-08T21:33:25.396544Z",
     "start_time": "2024-02-08T21:33:25.269700Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.18\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc02f47c17fc989c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-08T21:33:26.313794Z",
     "start_time": "2024-02-08T21:33:26.309338Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5754de339aacd468",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4a77c4e570d0e5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-08T21:33:30.771534Z",
     "start_time": "2024-02-08T21:33:30.765230Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of services: 531\n",
      "Number of timelines: 531\n"
     ]
    }
   ],
   "source": [
    "# Load all services\n",
    "with open('../data/nested_services.json', 'r') as f:\n",
    "    services = json.load(f)\n",
    "    \n",
    "services = pd.Series(child_obj['cName'] for obj in services['data'] for child_obj in obj['childServices'])\n",
    "print('Number of services:', len(services))\n",
    "    \n",
    "# Load all timelines\n",
    "with open('../data/timelines.json', 'r') as f:\n",
    "    timelines = json.load(f)\n",
    "\n",
    "timelines = pd.Series(obj['title'] for obj in timelines['data'])\n",
    "print('Number of timelines:', len(services))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5de1dba0d46937c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-08T21:33:33.739757Z",
     "start_time": "2024-02-08T21:33:33.732085Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>service</th>\n",
       "      <th>timeline</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Install/Repair HVAC</td>\n",
       "      <td>Around 1 day</td>\n",
       "      <td>\"Hello, I am in need of an HVAC technician to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Install/Repair HVAC</td>\n",
       "      <td>Around 5 days</td>\n",
       "      <td>Hello,\\n\\nI am writing to request an HVAC inst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Install/Repair AC</td>\n",
       "      <td>Around 1 day</td>\n",
       "      <td>Hello, \\nI am in need of your assistance with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Install/Repair AC</td>\n",
       "      <td>Around 5 days</td>\n",
       "      <td>Hi there,\\n\\nI am in need of a professional to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               service       timeline  \\\n",
       "0  Install/Repair HVAC   Around 1 day   \n",
       "1  Install/Repair HVAC  Around 5 days   \n",
       "2    Install/Repair AC   Around 1 day   \n",
       "3    Install/Repair AC  Around 5 days   \n",
       "\n",
       "                                         description  \n",
       "0  \"Hello, I am in need of an HVAC technician to ...  \n",
       "1  Hello,\\n\\nI am writing to request an HVAC inst...  \n",
       "2  Hello, \\nI am in need of your assistance with ...  \n",
       "3  Hi there,\\n\\nI am in need of a professional to...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "\n",
    "df = pd.read_csv('../data/data-gen/service_descriptions.csv', names=['service', 'timeline', 'description'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a8faeb3a3376db",
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Preprocessing using nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a50a3f4cf7bedd0",
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Split the data in training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c07e18e20ff21d70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-08T21:34:00.095340Z",
     "start_time": "2024-02-08T21:33:58.274013Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a8c38c82d6f453fa34f9ad8cad35820",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "659b363ecb074eadbb55395af5204f6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdbd1781d33b4ac6b73148839d112213",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0f88935c8d4420b82a922e47505398f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = 'bert-base-uncased'\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "def7ba70f5834470",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-08T21:35:02.452308Z",
     "start_time": "2024-02-08T21:35:02.436631Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[  101  1000  7592  1010  1045  2572  1999  2342  1997  2019  1044 24887\n",
      "  16661  2000 16500  2030  7192  2026 10808  1998 11520  2291  1012  2009\n",
      "   3849  2000  2022 15451 11263 27989  2075  1998  1045  2572  4039  2000\n",
      "  15176  1996  4860  1999  2026  2188  1012  1045  2052  6551  9120  2065\n",
      "   2023  2071  2022 10395  1999  1037 23259  5450  2004  1045  2031  2235\n",
      "   2336  1999  1996   102]\n",
      " [  101  7592  1010  1045  2572  3015  2000  5227  2019  1044 24887  8272\n",
      "   1013  7192  2326  2005  2026  2188  1012  2256  2783  1044 24887  2291\n",
      "   3849  2000  2022 15451 11263 27989  2075  1998  2057  2024 13417  8190\n",
      "   2007  4860  2491  1998  2250  4834  1012  2057  2052  6551  9120  2065\n",
      "   2619  2071  2272  1998  2202  1037  2298  2012  2009  2004  2574  2004\n",
      "   2825  1012 28946   102]\n",
      " [  101  7592  1010  1045  2572  1999  2342  1997  2115  5375  2007  2019\n",
      "   9353  8272  1013  7192  1012  1996  2783  9353  3131  1999  2026  2188\n",
      "   2003  2025 12285  7919  1998  1045  2572  1999  7143  2342  1997  1037\n",
      "   2658  2000  8081  2009  1012  1996  7715  2024  4803  1998  1045  2572\n",
      "   4039  2000  4562  1996  3684  2151  2936  1012  1045  2052  9120  2009\n",
      "   2065  2017  2071   102]\n",
      " [  101  7632  2045  1010  1045  2572  1999  2342  1997  1037  2658  2000\n",
      "   2393  2033  2007  1037 10232  4708  1012  2026  2250 14372  2291  2003\n",
      "   1999 18704  2342  1997  7192  1998  1045  2572  2559  2005  2619  2040\n",
      "   2064 12128  1998 18228 16500  2030  7192  2009  2005  2033  1012  1996\n",
      "   3684  2003  3352 24257  1010  1998  1045  2064  1005  1056  8984  2000\n",
      "   2175  2302  1037   102]], shape=(4, 64), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]], shape=(4, 64), dtype=int32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arshjot/anaconda3/envs/proveitML3_9/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2619: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the data\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "for description in df['description']:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "        description,\n",
    "        add_special_tokens=True,\n",
    "        max_length=64,\n",
    "        pad_to_max_length=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='tf'\n",
    "    )\n",
    "    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "    \n",
    "input_ids = tf.concat(input_ids, axis=0)\n",
    "attention_masks = tf.concat(attention_masks, axis=0)\n",
    "labels = tf.constant(df[['service', 'timeline']])\n",
    "\n",
    "print(input_ids)\n",
    "print(attention_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0203f0a3edd515",
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
